

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Library Reference &mdash; COMET 0.0.1 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/comet.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Train your own Metric" href="training.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> COMET
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="running.html">Running COMET</a></li>
<li class="toctree-l1"><a class="reference internal" href="models.html">COMET Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="training.html">Train your own Metric</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Library Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-comet.models.encoders.encoder_base">Multilingual Encoders</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#encoder-model-base">Encoder Model base</a></li>
<li class="toctree-l3"><a class="reference internal" href="#laser-encoder-model">LASER Encoder Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#bert-encoder">BERT Encoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="#xlm-r-encoder-model">XLM-R Encoder Model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-comet.models.model_base">Base Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#model-base">Model Base</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-comet.models.estimators.estimator_base">Estimators</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#estimator-base-model">Estimator Base Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#comet-estimator-model">Comet Estimator Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#quality-estimator-model">Quality Estimator Model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-comet.models.ranking.ranking_base">Translation Ranking Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#translation-ranking-base-model">Translation Ranking Base Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#comet-ranker-model">Comet Ranker Model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-comet.modules.feedforward">Auxiliar Modules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#feed-forward">Feed Forward</a></li>
<li class="toctree-l3"><a class="reference internal" href="#layer-wise-attention-mechanism">Layer-Wise Attention Mechanism</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">COMET</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Library Reference</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/library.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="library-reference">
<h1>Library Reference<a class="headerlink" href="#library-reference" title="Permalink to this headline">¶</a></h1>
<div class="section" id="module-comet.models.encoders.encoder_base">
<span id="multilingual-encoders"></span><h2>Multilingual Encoders<a class="headerlink" href="#module-comet.models.encoders.encoder_base" title="Permalink to this headline">¶</a></h2>
<div class="section" id="encoder-model-base">
<h3>Encoder Model base<a class="headerlink" href="#encoder-model-base" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>Module defining the common interface between all pretrained encoder models.</p>
</div></blockquote>
<dl class="py class">
<dt id="comet.models.encoders.encoder_base.Encoder">
<em class="property">class </em><code class="sig-prename descclassname">comet.models.encoders.encoder_base.</code><code class="sig-name descname">Encoder</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">tokenizer</span><span class="p">:</span> <span class="n">comet.tokenizers.tokenizer_base.TextEncoderBase</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/comet/models/encoders/encoder_base.html#Encoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.encoders.encoder_base.Encoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for an encoder model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>output_units</strong> – Number of output features that will be passed to the Estimator.</p>
</dd>
</dl>
<dl class="py method">
<dt id="comet.models.encoders.encoder_base.Encoder.check_lengths">
<code class="sig-name descname">check_lengths</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">tokens</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">lengths</span><span class="p">:</span> <span class="n">torch.Tensor</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/comet/models/encoders/encoder_base.html#Encoder.check_lengths"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.encoders.encoder_base.Encoder.check_lengths" title="Permalink to this definition">¶</a></dt>
<dd><p>Checks if lengths are not exceeded and warns user if so.</p>
</dd></dl>

<dl class="py method">
<dt id="comet.models.encoders.encoder_base.Encoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">tokens</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">lengths</span><span class="p">:</span> <span class="n">torch.Tensor</span></em><span class="sig-paren">)</span> &#x2192; Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><a class="reference internal" href="_modules/comet/models/encoders/encoder_base.html#Encoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.encoders.encoder_base.Encoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encodes a batch of sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tokens</strong> – Torch tensor with the input sequences [batch_size x seq_len].</p></li>
<li><p><strong>lengths</strong> – Torch tensor with the lenght of each sequence [seq_len].</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dictionary with <cite>sentemb</cite> (tensor with dims [batch_size x output_units]), <cite>wordemb</cite>
(tensor with dims [batch_size x seq_len x output_units]), <cite>mask</cite> (input mask),
<cite>all_layers</cite> (List with word_embeddings from all layers, <cite>extra</cite> (model specific outputs).</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.encoders.encoder_base.Encoder.freeze">
<code class="sig-name descname">freeze</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/comet/models/encoders/encoder_base.html#Encoder.freeze"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.encoders.encoder_base.Encoder.freeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Frezees the entire encoder network.</p>
</dd></dl>

<dl class="py method">
<dt id="comet.models.encoders.encoder_base.Encoder.freeze_embeddings">
<code class="sig-name descname">freeze_embeddings</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/comet/models/encoders/encoder_base.html#Encoder.freeze_embeddings"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.encoders.encoder_base.Encoder.freeze_embeddings" title="Permalink to this definition">¶</a></dt>
<dd><p>Frezees the embedding layer of the network to save some memory while training.</p>
</dd></dl>

<dl class="py method">
<dt id="comet.models.encoders.encoder_base.Encoder.from_pretrained">
<em class="property">classmethod </em><code class="sig-name descname">from_pretrained</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">hparams</span><span class="p">:</span> <span class="n">argparse.Namespace</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/comet/models/encoders/encoder_base.html#Encoder.from_pretrained"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.encoders.encoder_base.Encoder.from_pretrained" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that loads a pretrained encoder and the respective tokenizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Encoder model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.encoders.encoder_base.Encoder.layerwise_lr">
<code class="sig-name descname">layerwise_lr</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lr</span><span class="p">:</span> <span class="n">float</span></em>, <em class="sig-param"><span class="n">decay</span><span class="p">:</span> <span class="n">float</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/comet/models/encoders/encoder_base.html#Encoder.layerwise_lr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.encoders.encoder_base.Encoder.layerwise_lr" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>List with grouped model parameters with layer-wise decaying learning rate</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.encoders.encoder_base.Encoder.lm_head">
<em class="property">property </em><code class="sig-name descname">lm_head</code><a class="headerlink" href="#comet.models.encoders.encoder_base.Encoder.lm_head" title="Permalink to this definition">¶</a></dt>
<dd><p>Language modeling head.</p>
</dd></dl>

<dl class="py method">
<dt id="comet.models.encoders.encoder_base.Encoder.max_positions">
<em class="property">property </em><code class="sig-name descname">max_positions</code><a class="headerlink" href="#comet.models.encoders.encoder_base.Encoder.max_positions" title="Permalink to this definition">¶</a></dt>
<dd><p>Max number of tokens the encoder handles.</p>
</dd></dl>

<dl class="py method">
<dt id="comet.models.encoders.encoder_base.Encoder.num_layers">
<em class="property">property </em><code class="sig-name descname">num_layers</code><a class="headerlink" href="#comet.models.encoders.encoder_base.Encoder.num_layers" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of model layers available.</p>
</dd></dl>

<dl class="py method">
<dt id="comet.models.encoders.encoder_base.Encoder.output_units">
<em class="property">property </em><code class="sig-name descname">output_units</code><a class="headerlink" href="#comet.models.encoders.encoder_base.Encoder.output_units" title="Permalink to this definition">¶</a></dt>
<dd><p>Max number of tokens the encoder handles.</p>
</dd></dl>

<dl class="py method">
<dt id="comet.models.encoders.encoder_base.Encoder.prepare_sample">
<code class="sig-name descname">prepare_sample</code><span class="sig-paren">(</span><em class="sig-param">sample: List[str]) -&gt; (&lt;class 'torch.Tensor'&gt;</em>, <em class="sig-param">&lt;class 'torch.Tensor'&gt;</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/comet/models/encoders/encoder_base.html#Encoder.prepare_sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.encoders.encoder_base.Encoder.prepare_sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Receives a list of strings and applies model specific tokenization and vectorization.</p>
</dd></dl>

<dl class="py method">
<dt id="comet.models.encoders.encoder_base.Encoder.unfreeze">
<code class="sig-name descname">unfreeze</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/comet/models/encoders/encoder_base.html#Encoder.unfreeze"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.encoders.encoder_base.Encoder.unfreeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Unfrezees the entire encoder network.</p>
</dd></dl>

</dd></dl>

</div>
<span class="target" id="module-comet.models.encoders.laser"></span><div class="section" id="laser-encoder-model">
<h3>LASER Encoder Model<a class="headerlink" href="#laser-encoder-model" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>Pretrained LASER Encoder model from Facebook.
<a class="reference external" href="https://github.com/facebookresearch/LASER">https://github.com/facebookresearch/LASER</a></p>
<dl class="simple">
<dt>Check the original papers:</dt><dd><ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/1704.04154">https://arxiv.org/abs/1704.04154</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1812.10464">https://arxiv.org/abs/1812.10464</a></p></li>
</ul>
</dd>
</dl>
<p>and the original implementation: <a class="reference external" href="https://github.com/facebookresearch/LASER">https://github.com/facebookresearch/LASER</a></p>
</div></blockquote>
<dl class="py class">
<dt id="comet.models.encoders.laser.LASEREncoder">
<em class="property">class </em><code class="sig-prename descclassname">comet.models.encoders.laser.</code><code class="sig-name descname">LASEREncoder</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">num_embeddings</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">73640</span></em>, <em class="sig-param"><span class="n">padding_idx</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">1</span></em>, <em class="sig-param"><span class="n">embed_dim</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">320</span></em>, <em class="sig-param"><span class="n">hidden_size</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">512</span></em>, <em class="sig-param"><span class="n">num_layers</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">5</span></em>, <em class="sig-param"><span class="n">bidirectional</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">True</span></em>, <em class="sig-param"><span class="n">left_pad</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">True</span></em>, <em class="sig-param"><span class="n">padding_value</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">0.0</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/comet/models/encoders/laser.html#LASEREncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.encoders.laser.LASEREncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bidirectional LASER Encoder</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_embeddings</strong> – Size of the vocabulary (73640 BPE tokens).</p></li>
<li><p><strong>padding_idx</strong> – Index of the padding token in the vocabulary.</p></li>
<li><p><strong>embed_dim</strong> – Size of the embeddings.</p></li>
<li><p><strong>hidden_size</strong> – Number of features of the LSTM hidden layer.</p></li>
<li><p><strong>num_layers</strong> – Number of LSTM stacked layers.</p></li>
<li><p><strong>bidirectinal</strong> – Flag to initialize a Bidirectional LSTM.</p></li>
<li><p><strong>left_pad</strong> – If set to True the inputs can be left padded.
(internaly they will be converted to right padded inputs)</p></li>
<li><p><strong>padding_value</strong> – Value of the padding token.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="comet.models.encoders.laser.LASEREncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">tokens</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">lengths</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span> &#x2192; Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><a class="reference internal" href="_modules/comet/models/encoders/laser.html#LASEREncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.encoders.laser.LASEREncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encodes a batch of sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tokens</strong> – Torch tensor with the input sequences [batch_size x seq_len].</p></li>
<li><p><strong>lengths</strong> – Torch tensor with the lenght of each sequence [seq_len].</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dictionary with <cite>sentemb</cite> (tensor with dims [batch_size x output_units]), <cite>wordemb</cite>
(tensor with dims [batch_size x seq_len x output_units]), <cite>mask</cite> (input mask),
<cite>all_layers</cite> (List with word_embeddings from all layers, <cite>extra</cite> (tuple with the LSTM outputs,
hidden states and cell states).</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.encoders.laser.LASEREncoder.freeze_embeddings">
<code class="sig-name descname">freeze_embeddings</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/comet/models/encoders/laser.html#LASEREncoder.freeze_embeddings"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.encoders.laser.LASEREncoder.freeze_embeddings" title="Permalink to this definition">¶</a></dt>
<dd><p>Freezes the embedding layer of the network to save some memory while training.</p>
</dd></dl>

<dl class="py method">
<dt id="comet.models.encoders.laser.LASEREncoder.from_pretrained">
<em class="property">classmethod </em><code class="sig-name descname">from_pretrained</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">hparams</span><span class="p">:</span> <span class="n">argparse.Namespace</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/comet/models/encoders/laser.html#LASEREncoder.from_pretrained"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.encoders.laser.LASEREncoder.from_pretrained" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that loads a pretrained LASER encoder and the respective tokenizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hparams</strong> – Namespace.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>LASER Encoder model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.encoders.laser.LASEREncoder.max_positions">
<em class="property">property </em><code class="sig-name descname">max_positions</code><a class="headerlink" href="#comet.models.encoders.laser.LASEREncoder.max_positions" title="Permalink to this definition">¶</a></dt>
<dd><p>Max number of tokens the encoder handles.</p>
</dd></dl>

<dl class="py method">
<dt id="comet.models.encoders.laser.LASEREncoder.num_layers">
<em class="property">property </em><code class="sig-name descname">num_layers</code><a class="headerlink" href="#comet.models.encoders.laser.LASEREncoder.num_layers" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of model layers available.</p>
</dd></dl>

<dl class="py method">
<dt id="comet.models.encoders.laser.LASEREncoder.reorder_output">
<code class="sig-name descname">reorder_output</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">encoder_out</span><span class="p">:</span> <span class="n">Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">new_order</span><span class="p">:</span> <span class="n">torch.LongTensor</span></em><span class="sig-paren">)</span> &#x2192; Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><a class="reference internal" href="_modules/comet/models/encoders/laser.html#LASEREncoder.reorder_output"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.encoders.laser.LASEREncoder.reorder_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that reorders the LASER encoder outputs at the batch level.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>encoder_out</strong> – the output of the forward function.</p></li>
<li><p><strong>new_order</strong> – the new order inside the batch.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<span class="target" id="module-comet.models.encoders.bert"></span><div class="section" id="bert-encoder">
<h3>BERT Encoder<a class="headerlink" href="#bert-encoder" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>Pretrained BERT encoder from Hugging Face.</p>
</div></blockquote>
<dl class="py class">
<dt id="comet.models.encoders.bert.BERTEncoder">
<em class="property">class </em><code class="sig-prename descclassname">comet.models.encoders.bert.</code><code class="sig-name descname">BERTEncoder</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">tokenizer</span><span class="p">:</span> <span class="n">comet.tokenizers.hf_tokenizer.HFTextEncoder</span></em>, <em class="sig-param"><span class="n">hparams</span><span class="p">:</span> <span class="n">argparse.Namespace</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/comet/models/encoders/bert.html#BERTEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.encoders.bert.BERTEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>BERT encoder.
:param tokenizer: BERT text encoder.
:param hparams: ArgumentParser.</p>
<dl class="py method">
<dt id="comet.models.encoders.bert.BERTEncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">tokens</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">lengths</span><span class="p">:</span> <span class="n">torch.Tensor</span></em><span class="sig-paren">)</span> &#x2192; Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><a class="reference internal" href="_modules/comet/models/encoders/bert.html#BERTEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.encoders.bert.BERTEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encodes a batch of sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tokens</strong> – Torch tensor with the input sequences [batch_size x seq_len].</p></li>
<li><p><strong>lengths</strong> – Torch tensor with the lenght of each sequence [seq_len].</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dictionary with <cite>sentemb</cite> (tensor with dims [batch_size x output_units]), <cite>wordemb</cite>
(tensor with dims [batch_size x seq_len x output_units]), <cite>mask</cite> (input mask),
<cite>all_layers</cite> (List with word_embeddings from all layers), <cite>extra</cite> (tuple with the
last_hidden_state, the pooler_output representing  the entire sentence and the word
embeddings for all BERT layers).</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.encoders.bert.BERTEncoder.freeze_embeddings">
<code class="sig-name descname">freeze_embeddings</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/comet/models/encoders/bert.html#BERTEncoder.freeze_embeddings"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.encoders.bert.BERTEncoder.freeze_embeddings" title="Permalink to this definition">¶</a></dt>
<dd><p>Frezees the embedding layer of the network to save some memory while training.</p>
</dd></dl>

<dl class="py method">
<dt id="comet.models.encoders.bert.BERTEncoder.from_pretrained">
<em class="property">classmethod </em><code class="sig-name descname">from_pretrained</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">hparams</span><span class="p">:</span> <span class="n">argparse.Namespace</span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#comet.models.encoders.encoder_base.Encoder" title="comet.models.encoders.encoder_base.Encoder">comet.models.encoders.encoder_base.Encoder</a><a class="reference internal" href="_modules/comet/models/encoders/bert.html#BERTEncoder.from_pretrained"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.encoders.bert.BERTEncoder.from_pretrained" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that loads a pretrained encoder from Hugging Face.
:param hparams: Namespace.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Encoder model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.encoders.bert.BERTEncoder.layerwise_lr">
<code class="sig-name descname">layerwise_lr</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lr</span><span class="p">:</span> <span class="n">float</span></em>, <em class="sig-param"><span class="n">decay</span><span class="p">:</span> <span class="n">float</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/comet/models/encoders/bert.html#BERTEncoder.layerwise_lr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.encoders.bert.BERTEncoder.layerwise_lr" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>List with grouped model parameters with layer-wise decaying learning rate</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<span class="target" id="module-comet.models.encoders.xlmr"></span><div class="section" id="xlm-r-encoder-model">
<h3>XLM-R Encoder Model<a class="headerlink" href="#xlm-r-encoder-model" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>Pretrained XLM-RoBERTa from Fairseq framework.
<a class="reference external" href="https://github.com/pytorch/fairseq/tree/master/examples/xlmr">https://github.com/pytorch/fairseq/tree/master/examples/xlmr</a></p>
</div></blockquote>
<dl class="py class">
<dt id="comet.models.encoders.xlmr.XLMREncoder">
<em class="property">class </em><code class="sig-prename descclassname">comet.models.encoders.xlmr.</code><code class="sig-name descname">XLMREncoder</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">xlmr</span><span class="p">:</span> <span class="n">fairseq.models.roberta.model.XLMRModel</span></em>, <em class="sig-param"><span class="n">tokenizer</span><span class="p">:</span> <span class="n">comet.tokenizers.xlmr_tokenizer.XLMRTextEncoder</span></em>, <em class="sig-param"><span class="n">hparams</span><span class="p">:</span> <span class="n">argparse.Namespace</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/comet/models/encoders/xlmr.html#XLMREncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.encoders.xlmr.XLMREncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>XLM-RoBERTa encoder from Fairseq.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xlmr</strong> – XLM-R model to be used.</p></li>
<li><p><strong>tokenizer</strong> – XLM-R model tokenizer to be used.</p></li>
<li><p><strong>hparams</strong> – Namespace.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="comet.models.encoders.xlmr.XLMREncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">tokens</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">lengths</span><span class="p">:</span> <span class="n">torch.Tensor</span></em><span class="sig-paren">)</span> &#x2192; Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><a class="reference internal" href="_modules/comet/models/encoders/xlmr.html#XLMREncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.encoders.xlmr.XLMREncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encodes a batch of sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tokens</strong> – Torch tensor with the input sequences [batch_size x seq_len].</p></li>
<li><p><strong>lengths</strong> – Torch tensor with the length of each sequence [seq_len].</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dictionary with <cite>sentemb</cite> (tensor with dims [batch_size x output_units]), <cite>wordemb</cite>
(tensor with dims [batch_size x seq_len x output_units]), <cite>mask</cite> (input mask),
<cite>all_layers</cite> (List with word_embeddings from all layers), <cite>extra</cite> (tuple with all XLM-R layers).</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.encoders.xlmr.XLMREncoder.freeze_embeddings">
<code class="sig-name descname">freeze_embeddings</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/comet/models/encoders/xlmr.html#XLMREncoder.freeze_embeddings"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.encoders.xlmr.XLMREncoder.freeze_embeddings" title="Permalink to this definition">¶</a></dt>
<dd><p>Freezes the embedding layer of the network to save some memory while training.</p>
</dd></dl>

<dl class="py method">
<dt id="comet.models.encoders.xlmr.XLMREncoder.from_pretrained">
<em class="property">classmethod </em><code class="sig-name descname">from_pretrained</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">hparams</span><span class="p">:</span> <span class="n">argparse.Namespace</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/comet/models/encoders/xlmr.html#XLMREncoder.from_pretrained"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.encoders.xlmr.XLMREncoder.from_pretrained" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that loads a pretrained encoder and the respective tokenizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Encoder model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.encoders.xlmr.XLMREncoder.layerwise_lr">
<code class="sig-name descname">layerwise_lr</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lr</span><span class="p">:</span> <span class="n">float</span></em>, <em class="sig-param"><span class="n">decay</span><span class="p">:</span> <span class="n">float</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/comet/models/encoders/xlmr.html#XLMREncoder.layerwise_lr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.encoders.xlmr.XLMREncoder.layerwise_lr" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>List with grouped model parameters with layer-wise decaying learning rate</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.encoders.xlmr.XLMREncoder.lm_head">
<em class="property">property </em><code class="sig-name descname">lm_head</code><a class="headerlink" href="#comet.models.encoders.xlmr.XLMREncoder.lm_head" title="Permalink to this definition">¶</a></dt>
<dd><p>Language modeling head.</p>
</dd></dl>

</dd></dl>

</div>
</div>
<div class="section" id="module-comet.models.model_base">
<span id="base-model"></span><h2>Base Model<a class="headerlink" href="#module-comet.models.model_base" title="Permalink to this headline">¶</a></h2>
<div class="section" id="model-base">
<h3>Model Base<a class="headerlink" href="#model-base" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>Abstract base class used to build new modules inside COMET.
This class is just an extention of PyTorch Lightning main module:
<a class="reference external" href="https://pytorch-lightning.readthedocs.io/en/0.8.4/lightning-module.html">https://pytorch-lightning.readthedocs.io/en/0.8.4/lightning-module.html</a></p>
</div></blockquote>
<dl class="py class">
<dt id="comet.models.model_base.ModelBase">
<em class="property">class </em><code class="sig-prename descclassname">comet.models.model_base.</code><code class="sig-name descname">ModelBase</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">hparams</span><span class="p">:</span> <span class="n">argparse.Namespace</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/comet/models/model_base.html#ModelBase"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.model_base.ModelBase" title="Permalink to this definition">¶</a></dt>
<dd><p>Extends PyTorch Lightning with a common structure and interface
that will be shared across all architectures.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hparams</strong> – Namespace with hyper-parameters</p>
</dd>
</dl>
<dl class="py class">
<dt id="comet.models.model_base.ModelBase.ModelConfig">
<em class="property">class </em><code class="sig-name descname">ModelConfig</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">initial_data</span><span class="p">:</span> <span class="n">dict</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/comet/models/model_base.html#ModelBase.ModelConfig"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.model_base.ModelBase.ModelConfig" title="Permalink to this definition">¶</a></dt>
<dd><p>The ModelConfig class is used to define model hyper-parameters that
are used to initialize our Lightning Modules. These parameters are
then overwritted with the values defined in the YAML file and coverted
to a Namespace to initialize the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model</strong> – Model class name (to be replaced with the model specified in the YAML)</p>
</dd>
</dl>
<p>——————– Training Parameters ————————-</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_size</strong> – Batch size used during training.</p></li>
<li><p><strong>nr_frozen_epochs</strong> – Number of epochs we keep the encoder model frozen.</p></li>
<li><p><strong>keep_embeddings_frozen</strong> – Keeping the embeddings frozen is a usefull way to save some GPU memory usage.
This is critical to fine-tune large models in GPUs with less than 32GB memory.</p></li>
</ul>
</dd>
</dl>
<p>——————– Optimizer Parameters ————————-</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> – Optimizer class to be used.</p></li>
<li><p><strong>learning_rate</strong> – Overall learning rate.</p></li>
</ul>
</dd>
</dl>
<p>——————– Scheduler Parameters ————————-</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scheduler</strong> – Scheduler class to be used.</p></li>
<li><p><strong>warmup_steps</strong> – Warmup steps (only used for schedulers with warmup period).</p></li>
</ul>
</dd>
</dl>
<p>——————– Architecture Parameters ————————-</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>encoder_model</strong> – Encoder class to be used.</p></li>
<li><p><strong>pretrained_model</strong> – Encoder checkpoint (e.g. xlmr.base vs xlmr.large)</p></li>
<li><p><strong>pool</strong> – Pooling technique to extract the sentence embeddings.
Options: {max, avg, default, cls} where default uses the <cite>default</cite> sentence embedding
returned by the encoder (e.g. BERT pooler_output) and <cite>cls</cite> is the first token of the
sequence and depends on the selected layer.</p></li>
<li><p><strong>load_weights</strong> – Loads weights from a checkpoint file that match the architecture.</p></li>
</ul>
</dd>
</dl>
<p>——————– Data Parameters ————————-</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_path</strong> – Path to the training data.</p></li>
<li><p><strong>val_path</strong> – Path to the validation data.</p></li>
<li><p><strong>test_path</strong> – Path to the test data.</p></li>
<li><p><strong>loader_workers</strong> – Number of workers used to load and tokenize data during training.</p></li>
<li><p><strong>monitor</strong> – Metric to be displayed in tqdm bar. Same as trainer monitor flag!</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="comet.models.model_base.ModelBase.ModelConfig.model">
<code class="sig-name descname">model</code><em class="property">: str</em><em class="property"> = None</em><a class="headerlink" href="#comet.models.model_base.ModelBase.ModelConfig.model" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="comet.models.model_base.ModelBase.ModelConfig.namespace">
<code class="sig-name descname">namespace</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; argparse.Namespace<a class="reference internal" href="_modules/comet/models/model_base.html#ModelBase.ModelConfig.namespace"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.model_base.ModelBase.ModelConfig.namespace" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="comet.models.model_base.ModelBase.ModelConfig.test_path">
<code class="sig-name descname">test_path</code><em class="property">: str</em><em class="property"> = None</em><a class="headerlink" href="#comet.models.model_base.ModelBase.ModelConfig.test_path" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="comet.models.model_base.ModelBase.ModelConfig.train_path">
<code class="sig-name descname">train_path</code><em class="property">: str</em><em class="property"> = None</em><a class="headerlink" href="#comet.models.model_base.ModelBase.ModelConfig.train_path" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="comet.models.model_base.ModelBase.ModelConfig.val_path">
<code class="sig-name descname">val_path</code><em class="property">: str</em><em class="property"> = None</em><a class="headerlink" href="#comet.models.model_base.ModelBase.ModelConfig.val_path" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="comet.models.model_base.ModelBase.ModelConfig.warmup_steps">
<code class="sig-name descname">warmup_steps</code><em class="property">: int</em><em class="property"> = None</em><a class="headerlink" href="#comet.models.model_base.ModelBase.ModelConfig.warmup_steps" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py method">
<dt id="comet.models.model_base.ModelBase.compute_loss">
<code class="sig-name descname">compute_loss</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model_out</span><span class="p">:</span> <span class="n">Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">targets</span><span class="p">:</span> <span class="n">Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="_modules/comet/models/model_base.html#ModelBase.compute_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.model_base.ModelBase.compute_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes Loss value according to a loss function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_out</strong> – model specific output.</p></li>
<li><p><strong>targets</strong> – Target score values [batch_size]</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.model_base.ModelBase.compute_metrics">
<code class="sig-name descname">compute_metrics</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">outputs</span><span class="p">:</span> <span class="n">List<span class="p">[</span>Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><a class="reference internal" href="_modules/comet/models/model_base.html#ModelBase.compute_metrics"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.model_base.ModelBase.compute_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that computes metrics of interest based on the list of outputs
you defined in validation_step.</p>
</dd></dl>

<dl class="py method">
<dt id="comet.models.model_base.ModelBase.configure_optimizers">
<code class="sig-name descname">configure_optimizers</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Tuple<span class="p">[</span>List<span class="p">[</span>torch.optim.optimizer.Optimizer<span class="p">]</span><span class="p">, </span>List<span class="p">[</span>torch.optim.lr_scheduler.LambdaLR<span class="p">]</span><span class="p">]</span><a class="reference internal" href="_modules/comet/models/model_base.html#ModelBase.configure_optimizers"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.model_base.ModelBase.configure_optimizers" title="Permalink to this definition">¶</a></dt>
<dd><p>Function for setting up the optimizers and the schedulers to be used during training.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>List with as many optimizers as we need and a list with the respective schedulers.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.model_base.ModelBase.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span> &#x2192; Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><a class="reference internal" href="_modules/comet/models/model_base.html#ModelBase.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.model_base.ModelBase.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>PyTorch Forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Dictionary with model outputs to be passed to the loss function.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.model_base.ModelBase.freeze_encoder">
<code class="sig-name descname">freeze_encoder</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/comet/models/model_base.html#ModelBase.freeze_encoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.model_base.ModelBase.freeze_encoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Freezes the encoder layer.</p>
</dd></dl>

<dl class="py method">
<dt id="comet.models.model_base.ModelBase.langid">
<code class="sig-name descname">langid</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">segment</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; str<a class="reference internal" href="_modules/comet/models/model_base.html#ModelBase.langid"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.model_base.ModelBase.langid" title="Permalink to this definition">¶</a></dt>
<dd><p>Auxiliar function to identify the language of a specific segment.
Useful for detecting MT hypothesis that DO NOT TRANSLATE the source. These segments
will be scored high due to its similarity to the source.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>segment</strong> – String with the text we wish to identify the langauge.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Language code (un for <cite>unknown</cite> languages)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.model_base.ModelBase.on_epoch_end">
<code class="sig-name descname">on_epoch_end</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/comet/models/model_base.html#ModelBase.on_epoch_end"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.model_base.ModelBase.on_epoch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Hook used to unfreeze encoder during training.</p>
</dd></dl>

<dl class="py method">
<dt id="comet.models.model_base.ModelBase.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">samples</span><span class="p">:</span> <span class="n">Dict<span class="p">[</span>str<span class="p">, </span>str<span class="p">]</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/comet/models/model_base.html#ModelBase.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.model_base.ModelBase.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that runs a model prediction,</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>samples</strong> – dictionary with expected model sequences.
You can also pass a list of dictionaries to predict an entire batch.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dictionary with input samples + scores and list with just the scores.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.model_base.ModelBase.prepare_sample">
<code class="sig-name descname">prepare_sample</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sample</span><span class="p">:</span> <span class="n">List<span class="p">[</span>Dict<span class="p">[</span>str<span class="p">, </span>Union<span class="p">[</span>str<span class="p">, </span>float<span class="p">]</span><span class="p">]</span><span class="p">]</span></span></em>, <em class="sig-param"><span class="n">inference</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em><span class="sig-paren">)</span> &#x2192; Union<span class="p">[</span>Tuple<span class="p">[</span>Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><span class="p">, </span>Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><span class="p">]</span><span class="p">, </span>Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><span class="p">]</span><a class="reference internal" href="_modules/comet/models/model_base.html#ModelBase.prepare_sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.model_base.ModelBase.prepare_sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that prepares a sample to input the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sample</strong> – List of dictionaries.</p></li>
<li><p><strong>inference</strong> – If set to true prepares only the model inputs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tuple with 2 dictionaries (model inputs and targets). If <cite>inference=True</cite>
returns only the model inputs.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.model_base.ModelBase.read_csv">
<code class="sig-name descname">read_csv</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">path</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; List<span class="p">[</span>dict<span class="p">]</span><a class="reference internal" href="_modules/comet/models/model_base.html#ModelBase.read_csv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.model_base.ModelBase.read_csv" title="Permalink to this definition">¶</a></dt>
<dd><p>Reads a comma separated value file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>path</strong> – path to a csv file.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of records as dictionaries</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.model_base.ModelBase.setup">
<code class="sig-name descname">setup</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">stage</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/comet/models/model_base.html#ModelBase.setup"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.model_base.ModelBase.setup" title="Permalink to this definition">¶</a></dt>
<dd><p>Data preparation function called before training by Lightning.
Equivalent to the prepare_data in previous Lightning Versions</p>
</dd></dl>

<dl class="py method">
<dt id="comet.models.model_base.ModelBase.test_dataloader">
<code class="sig-name descname">test_dataloader</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; torch.utils.data.dataloader.DataLoader<a class="reference internal" href="_modules/comet/models/model_base.html#ModelBase.test_dataloader"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.model_base.ModelBase.test_dataloader" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that loads the validation set.</p>
</dd></dl>

<dl class="py method">
<dt id="comet.models.model_base.ModelBase.test_epoch_end">
<code class="sig-name descname">test_epoch_end</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">outputs</span><span class="p">:</span> <span class="n">List<span class="p">[</span>Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; Dict<span class="p">[</span>str<span class="p">, </span>Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><span class="p">]</span><a class="reference internal" href="_modules/comet/models/model_base.html#ModelBase.test_epoch_end"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.model_base.ModelBase.test_epoch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes metrics.</p>
</dd></dl>

<dl class="py method">
<dt id="comet.models.model_base.ModelBase.test_step">
<code class="sig-name descname">test_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">batch</span><span class="p">:</span> <span class="n">Tuple<span class="p">[</span>Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><span class="p">, </span>Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><span class="p">]</span></span></em>, <em class="sig-param"><span class="n">batch_nb</span><span class="p">:</span> <span class="n">int</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span> &#x2192; Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><a class="reference internal" href="_modules/comet/models/model_base.html#ModelBase.test_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.model_base.ModelBase.test_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Redirects to the validation_step function</p>
</dd></dl>

<dl class="py method">
<dt id="comet.models.model_base.ModelBase.train_dataloader">
<code class="sig-name descname">train_dataloader</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; torch.utils.data.dataloader.DataLoader<a class="reference internal" href="_modules/comet/models/model_base.html#ModelBase.train_dataloader"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.model_base.ModelBase.train_dataloader" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that loads the train set.</p>
</dd></dl>

<dl class="py method">
<dt id="comet.models.model_base.ModelBase.training_step">
<code class="sig-name descname">training_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">batch</span><span class="p">:</span> <span class="n">Tuple<span class="p">[</span>Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><span class="p">, </span>Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><span class="p">]</span></span></em>, <em class="sig-param"><span class="n">batch_nb</span><span class="p">:</span> <span class="n">int</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span> &#x2192; Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><a class="reference internal" href="_modules/comet/models/model_base.html#ModelBase.training_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.model_base.ModelBase.training_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Runs one training step.
This usually consists in the forward function followed by the loss function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> – The output of your prepare_sample function.</p></li>
<li><p><strong>batch_nb</strong> – Integer displaying which batch this is.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>dictionary containing the loss and the metrics to be added to the lightning logger.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.model_base.ModelBase.unfreeze_encoder">
<code class="sig-name descname">unfreeze_encoder</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/comet/models/model_base.html#ModelBase.unfreeze_encoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.model_base.ModelBase.unfreeze_encoder" title="Permalink to this definition">¶</a></dt>
<dd><p>un-freezes the encoder layer.</p>
</dd></dl>

<dl class="py method">
<dt id="comet.models.model_base.ModelBase.val_dataloader">
<code class="sig-name descname">val_dataloader</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; torch.utils.data.dataloader.DataLoader<a class="reference internal" href="_modules/comet/models/model_base.html#ModelBase.val_dataloader"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.model_base.ModelBase.val_dataloader" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that loads the validation set.</p>
</dd></dl>

<dl class="py method">
<dt id="comet.models.model_base.ModelBase.validation_epoch_end">
<code class="sig-name descname">validation_epoch_end</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">outputs</span><span class="p">:</span> <span class="n">List<span class="p">[</span>Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; Dict<span class="p">[</span>str<span class="p">, </span>Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><span class="p">]</span><a class="reference internal" href="_modules/comet/models/model_base.html#ModelBase.validation_epoch_end"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.model_base.ModelBase.validation_epoch_end" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Function that takes as input a list of dictionaries returned by the validation_step</dt><dd><p>and measures the model performance accross the entire validation set.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>outputs</strong> – </p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dictionary with metrics to be added to the lightning logger.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.model_base.ModelBase.validation_step">
<code class="sig-name descname">validation_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">batch</span><span class="p">:</span> <span class="n">Tuple<span class="p">[</span>Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><span class="p">, </span>Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><span class="p">]</span></span></em>, <em class="sig-param"><span class="n">batch_nb</span><span class="p">:</span> <span class="n">int</span></em>, <em class="sig-param"><span class="n">dataloader_idx</span><span class="p">:</span> <span class="n">int</span></em><span class="sig-paren">)</span> &#x2192; Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><a class="reference internal" href="_modules/comet/models/model_base.html#ModelBase.validation_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.model_base.ModelBase.validation_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Similar to the training step but with the model in eval mode.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> – The output of your prepare_sample function.</p></li>
<li><p><strong>batch_nb</strong> – Integer displaying which batch this is.</p></li>
<li><p><strong>dataloader_idx</strong> – Integer displaying which dataloader this is.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>dictionary passed to the validation_end function.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>
<div class="section" id="module-comet.models.estimators.estimator_base">
<span id="estimators"></span><h2>Estimators<a class="headerlink" href="#module-comet.models.estimators.estimator_base" title="Permalink to this headline">¶</a></h2>
<div class="section" id="estimator-base-model">
<h3>Estimator Base Model<a class="headerlink" href="#estimator-base-model" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>Abstract base class used to build new estimator models
inside COMET.</p>
</div></blockquote>
<dl class="py class">
<dt id="comet.models.estimators.estimator_base.Estimator">
<em class="property">class </em><code class="sig-prename descclassname">comet.models.estimators.estimator_base.</code><code class="sig-name descname">Estimator</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">hparams</span><span class="p">:</span> <span class="n">argparse.Namespace</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/comet/models/estimators/estimator_base.html#Estimator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.estimators.estimator_base.Estimator" title="Permalink to this definition">¶</a></dt>
<dd><p>Estimator base class that uses an Encoder to encode sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hparams</strong> – Namespace containing the hyperparameters.</p>
</dd>
</dl>
<dl class="py class">
<dt id="comet.models.estimators.estimator_base.Estimator.ModelConfig">
<em class="property">class </em><code class="sig-name descname">ModelConfig</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">initial_data</span><span class="p">:</span> <span class="n">dict</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/comet/models/estimators/estimator_base.html#Estimator.ModelConfig"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.estimators.estimator_base.Estimator.ModelConfig" title="Permalink to this definition">¶</a></dt>
<dd><p>Estimator ModelConfig:</p>
<p>————————— Encoder —————————————–</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>encoder_learning_rate</strong> – Learning rate used for the encoder model.</p></li>
<li><p><strong>layerwise_decay</strong> – Decay for the layer wise learning rates. If 1.0 no decay is applied.</p></li>
<li><p><strong>layer</strong> – Layer that will be used to extract embeddings. If ‘mix’ embeddings
from all layers are combined with a layer-wise attention mechanism</p></li>
<li><p><strong>scalar_mix_dropout</strong> – If layer=’mix’ we can regularize layer’s importance by
with a given probability setting that weight to - inf before softmax.</p></li>
</ul>
</dd>
</dl>
<p>————————- Feed Forward —————————————</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>loss</strong> – Loss function to be used (options: binary_xent, mse).</p></li>
<li><p><strong>hidden_sizes</strong> – String with size of the hidden layers in the feedforward.</p></li>
<li><p><strong>activations</strong> – Activation functions to be used in the feedforward</p></li>
<li><p><strong>dropout</strong> – Dropout probability to be applied to the feedforward</p></li>
<li><p><strong>final_activation</strong> – Activation function to be applied after getting the
final regression score. Set to False if you wish to perform an ‘unbounded’ regression.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.estimators.estimator_base.Estimator.compute_loss">
<code class="sig-name descname">compute_loss</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model_out</span><span class="p">:</span> <span class="n">Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">targets</span><span class="p">:</span> <span class="n">Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="_modules/comet/models/estimators/estimator_base.html#Estimator.compute_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.estimators.estimator_base.Estimator.compute_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes Loss value according to a loss function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_out</strong> – model specific output. Must contain a key ‘score’ with
a tensor [batch_size x 1] with model predictions</p></li>
<li><p><strong>targets</strong> – Target score values [batch_size]</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.estimators.estimator_base.Estimator.compute_metrics">
<code class="sig-name descname">compute_metrics</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">outputs</span><span class="p">:</span> <span class="n">List<span class="p">[</span>Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; dict<a class="reference internal" href="_modules/comet/models/estimators/estimator_base.html#Estimator.compute_metrics"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.estimators.estimator_base.Estimator.compute_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>Private function that computes metrics of interest based on model predictions and
respective targets.</p>
</dd></dl>

<dl class="py method">
<dt id="comet.models.estimators.estimator_base.Estimator.document_predict">
<code class="sig-name descname">document_predict</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">documents</span><span class="p">:</span> <span class="n">List<span class="p">[</span>Dict<span class="p">[</span>str<span class="p">, </span>List<span class="p">[</span>str<span class="p">]</span><span class="p">]</span><span class="p">]</span></span></em>, <em class="sig-param"><span class="n">cuda</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em>, <em class="sig-param"><span class="n">show_progress</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/comet/models/estimators/estimator_base.html#Estimator.document_predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.estimators.estimator_base.Estimator.document_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that scores entire documents by processing all segments in parallel.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>documents</strong> – List of dictionaries with ‘mt’, ‘src’ and ‘ref’ keys where each key is
a list of segments.</p></li>
<li><p><strong>cuda</strong> – Flag that runs inference using 1 single GPU.</p></li>
<li><p><strong>show_progress</strong> – Flag to show progress during inference of multiple examples.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>tuple with Dictionary with original samples and predicted document score, micro
average scores, macro average scores.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.estimators.estimator_base.Estimator.get_sentence_embedding">
<code class="sig-name descname">get_sentence_embedding</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">tokens</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">lengths</span><span class="p">:</span> <span class="n">torch.Tensor</span></em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="_modules/comet/models/estimators/estimator_base.html#Estimator.get_sentence_embedding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.estimators.estimator_base.Estimator.get_sentence_embedding" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Auxiliar function that extracts sentence embeddings for</dt><dd><p>a single sentence.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tokens</strong> – sequences [batch_size x seq_len]</p></li>
<li><p><strong>lengths</strong> – lengths [batch_size]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>torch.Tensor [batch_size x hidden_size]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.estimators.estimator_base.Estimator.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">samples</span><span class="p">:</span> <span class="n">List<span class="p">[</span>Dict<span class="p">[</span>str<span class="p">, </span>str<span class="p">]</span><span class="p">]</span></span></em>, <em class="sig-param"><span class="n">cuda</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em>, <em class="sig-param"><span class="n">show_progress</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/comet/models/estimators/estimator_base.html#Estimator.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.estimators.estimator_base.Estimator.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that runs a model prediction,</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> – List of dictionaries with ‘mt’ and ‘ref’ keys.</p></li>
<li><p><strong>cuda</strong> – Flag that runs inference using 1 single GPU.</p></li>
<li><p><strong>show_progress</strong> – Flag to show progress during inference of multiple examples.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dictionary with original samples, predicted scores and langid results for SRC and MT
+ list of predicted scores</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.estimators.estimator_base.Estimator.read_csv">
<code class="sig-name descname">read_csv</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">path</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; List<span class="p">[</span>dict<span class="p">]</span><a class="reference internal" href="_modules/comet/models/estimators/estimator_base.html#Estimator.read_csv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.estimators.estimator_base.Estimator.read_csv" title="Permalink to this definition">¶</a></dt>
<dd><p>Reads a comma separated value file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>path</strong> – path to a csv file.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of records as dictionaries</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<span class="target" id="module-comet.models.estimators.comet_estimator"></span><div class="section" id="comet-estimator-model">
<h3>Comet Estimator Model<a class="headerlink" href="#comet-estimator-model" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>Comet Estimator predicts a quality score for the
hyphotesis (e.g: the MT text) by looking at reference, source and MT.</p>
</div></blockquote>
<dl class="py class">
<dt id="comet.models.estimators.comet_estimator.CometEstimator">
<em class="property">class </em><code class="sig-prename descclassname">comet.models.estimators.comet_estimator.</code><code class="sig-name descname">CometEstimator</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">hparams</span><span class="p">:</span> <span class="n">argparse.Namespace</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/comet/models/estimators/comet_estimator.html#CometEstimator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.estimators.comet_estimator.CometEstimator" title="Permalink to this definition">¶</a></dt>
<dd><p>Estimator class that uses a pretrained encoder to extract features from
the sequences and then passes those features to a feed forward estimator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hparams</strong> – Namespace containing the hyperparameters.</p>
</dd>
</dl>
<dl class="py class">
<dt id="comet.models.estimators.comet_estimator.CometEstimator.ModelConfig">
<em class="property">class </em><code class="sig-name descname">ModelConfig</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">initial_data</span><span class="p">:</span> <span class="n">dict</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/comet/models/estimators/comet_estimator.html#CometEstimator.ModelConfig"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.estimators.comet_estimator.CometEstimator.ModelConfig" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="comet.models.estimators.comet_estimator.CometEstimator.configure_optimizers">
<code class="sig-name descname">configure_optimizers</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Tuple<span class="p">[</span>List<span class="p">[</span>torch.optim.optimizer.Optimizer<span class="p">]</span><span class="p">, </span>List<span class="p">[</span>torch.optim.lr_scheduler.LambdaLR<span class="p">]</span><span class="p">]</span><a class="reference internal" href="_modules/comet/models/estimators/comet_estimator.html#CometEstimator.configure_optimizers"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.estimators.comet_estimator.CometEstimator.configure_optimizers" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets different Learning rates for different parameter groups.</p>
</dd></dl>

<dl class="py method">
<dt id="comet.models.estimators.comet_estimator.CometEstimator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">src_tokens</span><span class="p">:</span> <span class="n">None._VariableFunctions.tensor</span></em>, <em class="sig-param"><span class="n">mt_tokens</span><span class="p">:</span> <span class="n">None._VariableFunctions.tensor</span></em>, <em class="sig-param"><span class="n">ref_tokens</span><span class="p">:</span> <span class="n">None._VariableFunctions.tensor</span></em>, <em class="sig-param"><span class="n">src_lengths</span><span class="p">:</span> <span class="n">None._VariableFunctions.tensor</span></em>, <em class="sig-param"><span class="n">mt_lengths</span><span class="p">:</span> <span class="n">None._VariableFunctions.tensor</span></em>, <em class="sig-param"><span class="n">ref_lengths</span><span class="p">:</span> <span class="n">None._VariableFunctions.tensor</span></em>, <em class="sig-param"><span class="n">alt_tokens</span><span class="p">:</span> <span class="n">None._VariableFunctions.tensor</span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">alt_lengths</span><span class="p">:</span> <span class="n">None._VariableFunctions.tensor</span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span> &#x2192; Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><a class="reference internal" href="_modules/comet/models/estimators/comet_estimator.html#CometEstimator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.estimators.comet_estimator.CometEstimator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that encodes both Source, MT and Reference and returns a quality score.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>src_tokens</strong> – SRC sequences [batch_size x src_seq_len]</p></li>
<li><p><strong>mt_tokens</strong> – MT sequences [batch_size x mt_seq_len]</p></li>
<li><p><strong>ref_tokens</strong> – REF sequences [batch_size x ref_seq_len]</p></li>
<li><p><strong>src_lengths</strong> – SRC lengths [batch_size]</p></li>
<li><p><strong>mt_lengths</strong> – MT lengths [batch_size]</p></li>
<li><p><strong>ref_lengths</strong> – REF lengths [batch_size]</p></li>
<li><p><strong>alt_tokens</strong> – Alternative REF sequences [batch_size x alt_seq_len]</p></li>
<li><p><strong>alt_lengths</strong> – Alternative REF lengths [batch_size]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dictionary with model outputs to be passed to the loss function.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.estimators.comet_estimator.CometEstimator.prepare_sample">
<code class="sig-name descname">prepare_sample</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sample</span><span class="p">:</span> <span class="n">List<span class="p">[</span>Dict<span class="p">[</span>str<span class="p">, </span>Union<span class="p">[</span>str<span class="p">, </span>float<span class="p">]</span><span class="p">]</span><span class="p">]</span></span></em>, <em class="sig-param"><span class="n">inference</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em><span class="sig-paren">)</span> &#x2192; Union<span class="p">[</span>Tuple<span class="p">[</span>Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><span class="p">, </span>Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><span class="p">]</span><span class="p">, </span>Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><span class="p">]</span><a class="reference internal" href="_modules/comet/models/estimators/comet_estimator.html#CometEstimator.prepare_sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.estimators.comet_estimator.CometEstimator.prepare_sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that prepares a sample to input the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sample</strong> – list of dictionaries.</p></li>
<li><p><strong>inference</strong> – If set to true prepares only the model inputs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tuple with 2 dictionaries (model inputs and targets).
If <cite>inference=True</cite> returns only the model inputs.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<span class="target" id="module-comet.models.estimators.quality_estimator"></span><div class="section" id="quality-estimator-model">
<h3>Quality Estimator Model<a class="headerlink" href="#quality-estimator-model" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>Quality Estimator Model estimates a quality score for the hyphotesis (e.g: the MT text)
by looking only at source and MT.</p>
</div></blockquote>
<dl class="py class">
<dt id="comet.models.estimators.quality_estimator.QualityEstimator">
<em class="property">class </em><code class="sig-prename descclassname">comet.models.estimators.quality_estimator.</code><code class="sig-name descname">QualityEstimator</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">hparams</span><span class="p">:</span> <span class="n">argparse.Namespace</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/comet/models/estimators/quality_estimator.html#QualityEstimator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.estimators.quality_estimator.QualityEstimator" title="Permalink to this definition">¶</a></dt>
<dd><p>Estimator class that uses a pretrained encoder to extract features from
the sequences and then passes those features to a feed forward estimator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hparams</strong> – Namespace containing the hyperparameters.</p>
</dd>
</dl>
<dl class="py method">
<dt id="comet.models.estimators.quality_estimator.QualityEstimator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">mt_tokens</span><span class="p">:</span> <span class="n">None._VariableFunctions.tensor</span></em>, <em class="sig-param"><span class="n">src_tokens</span><span class="p">:</span> <span class="n">None._VariableFunctions.tensor</span></em>, <em class="sig-param"><span class="n">mt_lengths</span><span class="p">:</span> <span class="n">None._VariableFunctions.tensor</span></em>, <em class="sig-param"><span class="n">src_lengths</span><span class="p">:</span> <span class="n">None._VariableFunctions.tensor</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span> &#x2192; Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><a class="reference internal" href="_modules/comet/models/estimators/quality_estimator.html#QualityEstimator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.estimators.quality_estimator.QualityEstimator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that encodes both Source, MT and returns a quality score.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mt_tokens</strong> – MT sequences [batch_size x mt_seq_len]</p></li>
<li><p><strong>src_tokens</strong> – SRC sequences [batch_size x src_seq_len]</p></li>
<li><p><strong>mt_lengths</strong> – MT lengths [batch_size]</p></li>
<li><p><strong>src_lengths</strong> – SRC lengths [batch_size]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dictionary with model outputs to be passed to the loss function.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.estimators.quality_estimator.QualityEstimator.prepare_sample">
<code class="sig-name descname">prepare_sample</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sample</span><span class="p">:</span> <span class="n">List<span class="p">[</span>Dict<span class="p">[</span>str<span class="p">, </span>Union<span class="p">[</span>str<span class="p">, </span>float<span class="p">]</span><span class="p">]</span><span class="p">]</span></span></em>, <em class="sig-param"><span class="n">inference</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em><span class="sig-paren">)</span> &#x2192; Union<span class="p">[</span>Tuple<span class="p">[</span>Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><span class="p">, </span>Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><span class="p">]</span><span class="p">, </span>Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><span class="p">]</span><a class="reference internal" href="_modules/comet/models/estimators/quality_estimator.html#QualityEstimator.prepare_sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.estimators.quality_estimator.QualityEstimator.prepare_sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that prepares a sample to input the model.
:param sample: list of dictionaries.
:param inference: If set to true prepares only the model inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Tuple with 2 dictionaries (model inputs and targets).
If <cite>inference=True</cite> returns only the model inputs.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.estimators.quality_estimator.QualityEstimator.read_csv">
<code class="sig-name descname">read_csv</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">path</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; List<span class="p">[</span>dict<span class="p">]</span><a class="reference internal" href="_modules/comet/models/estimators/quality_estimator.html#QualityEstimator.read_csv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.estimators.quality_estimator.QualityEstimator.read_csv" title="Permalink to this definition">¶</a></dt>
<dd><p>Reads a comma separated value file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>path</strong> – path to a csv file.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of records as dictionaries</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>
<div class="section" id="module-comet.models.ranking.ranking_base">
<span id="translation-ranking-model"></span><h2>Translation Ranking Model<a class="headerlink" href="#module-comet.models.ranking.ranking_base" title="Permalink to this headline">¶</a></h2>
<div class="section" id="translation-ranking-base-model">
<h3>Translation Ranking Base Model<a class="headerlink" href="#translation-ranking-base-model" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>Abstract base class used to build new ranking systems inside COMET.
This task consists of ranking “good” translations above “worse” ones.</p>
</div></blockquote>
<dl class="py class">
<dt id="comet.models.ranking.ranking_base.RankingBase">
<em class="property">class </em><code class="sig-prename descclassname">comet.models.ranking.ranking_base.</code><code class="sig-name descname">RankingBase</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">hparams</span><span class="p">:</span> <span class="n">argparse.Namespace</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/comet/models/ranking/ranking_base.html#RankingBase"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.ranking.ranking_base.RankingBase" title="Permalink to this definition">¶</a></dt>
<dd><p>Ranking Model base class used to fine-tune pretrained models such as XLM-R
to produce better sentence embeddings by optmizing Triplet Margin Loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hparams</strong> – Namespace containing the hyperparameters.</p>
</dd>
</dl>
<dl class="py method">
<dt id="comet.models.ranking.ranking_base.RankingBase.compute_loss">
<code class="sig-name descname">compute_loss</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model_out</span><span class="p">:</span> <span class="n">Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span></span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="_modules/comet/models/ranking/ranking_base.html#RankingBase.compute_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.ranking.ranking_base.RankingBase.compute_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes Triplet Margin Loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model_out</strong> – model specific output with reference, pos and neg
sentence embeddings.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.ranking.ranking_base.RankingBase.compute_metrics">
<code class="sig-name descname">compute_metrics</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">outputs</span><span class="p">:</span> <span class="n">List<span class="p">[</span>Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><a class="reference internal" href="_modules/comet/models/ranking/ranking_base.html#RankingBase.compute_metrics"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.ranking.ranking_base.RankingBase.compute_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes WMT19 shared task kendall tau like metric.</p>
</dd></dl>

<dl class="py method">
<dt id="comet.models.ranking.ranking_base.RankingBase.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ref_tokens</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">pos_tokens</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">neg_tokens</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">ref_lengths</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">pos_lengths</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">neg_lengths</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span> &#x2192; Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><a class="reference internal" href="_modules/comet/models/ranking/ranking_base.html#RankingBase.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.ranking.ranking_base.RankingBase.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that encodes the reference, positive samples and negative samples
and returns embeddings for the triplet.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ref_tokens</strong> – reference sequences [batch_size x ref_seq_len]</p></li>
<li><p><strong>pos_tokens</strong> – positive sequences [batch_size x pos_seq_len]</p></li>
<li><p><strong>neg_tokens</strong> – negative sequences [batch_size x neg_seq_len]</p></li>
<li><p><strong>ref_lengths</strong> – reference lengths [batch_size]</p></li>
<li><p><strong>pos_lengths</strong> – positive lengths [batch_size]</p></li>
<li><p><strong>neg_lengths</strong> – negative lengths [batch_size]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dictionary with model outputs to be passed to the loss function.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.ranking.ranking_base.RankingBase.get_sentence_embedding">
<code class="sig-name descname">get_sentence_embedding</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">tokens</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">lengths</span><span class="p">:</span> <span class="n">torch.Tensor</span></em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="_modules/comet/models/ranking/ranking_base.html#RankingBase.get_sentence_embedding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.ranking.ranking_base.RankingBase.get_sentence_embedding" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Auxiliar function that extracts sentence embeddings for</dt><dd><p>a single sentence.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tokens</strong> – sequences [batch_size x seq_len]</p></li>
<li><p><strong>lengths</strong> – lengths [batch_size]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>torch.Tensor [batch_size x hidden_size]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.ranking.ranking_base.RankingBase.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">samples</span><span class="p">:</span> <span class="n">Dict<span class="p">[</span>str<span class="p">, </span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">cuda</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em>, <em class="sig-param"><span class="n">show_progress</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/comet/models/ranking/ranking_base.html#RankingBase.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.ranking.ranking_base.RankingBase.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that runs a model prediction,</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> – List of dictionaries with ‘mt’ and ‘ref’ keys.</p></li>
<li><p><strong>cuda</strong> – Flag that runs inference using 1 single GPU.</p></li>
<li><p><strong>show_progress</strong> – Flag to show progress during inference of multiple examples.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dictionary with original samples + predicted scores and list of predicted scores</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.ranking.ranking_base.RankingBase.read_csv">
<code class="sig-name descname">read_csv</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">path</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; List<span class="p">[</span>dict<span class="p">]</span><a class="reference internal" href="_modules/comet/models/ranking/ranking_base.html#RankingBase.read_csv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.ranking.ranking_base.RankingBase.read_csv" title="Permalink to this definition">¶</a></dt>
<dd><p>Reads a comma separated value file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>path</strong> – path to a csv file.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of records as dictionaries</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<span class="target" id="module-comet.models.ranking.comet_ranker"></span><div class="section" id="comet-ranker-model">
<h3>Comet Ranker Model<a class="headerlink" href="#comet-ranker-model" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>The goal of this model is to rank good translations closer to the reference and source text
and bad translations further by a small margin.</p>
<p><a class="reference external" href="https://pytorch.org/docs/stable/nn.html#tripletmarginloss">https://pytorch.org/docs/stable/nn.html#tripletmarginloss</a></p>
</div></blockquote>
<dl class="py class">
<dt id="comet.models.ranking.comet_ranker.CometRanker">
<em class="property">class </em><code class="sig-prename descclassname">comet.models.ranking.comet_ranker.</code><code class="sig-name descname">CometRanker</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">hparams</span><span class="p">:</span> <span class="n">argparse.Namespace</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/comet/models/ranking/comet_ranker.html#CometRanker"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.ranking.comet_ranker.CometRanker" title="Permalink to this definition">¶</a></dt>
<dd><p>Comet Ranker class that uses a pretrained encoder to extract features
from the sequences and then passes those features through a Triplet Margin Loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hparams</strong> – Namespace containing the hyperparameters.</p>
</dd>
</dl>
<dl class="py method">
<dt id="comet.models.ranking.comet_ranker.CometRanker.compute_loss">
<code class="sig-name descname">compute_loss</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model_out</span><span class="p">:</span> <span class="n">Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span></span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="_modules/comet/models/ranking/comet_ranker.html#CometRanker.compute_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.ranking.comet_ranker.CometRanker.compute_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes Triplet Margin Loss for both the reference and the source.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model_out</strong> – model specific output with src_anchor, ref_anchor, pos and neg
sentence embeddings.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.ranking.comet_ranker.CometRanker.compute_metrics">
<code class="sig-name descname">compute_metrics</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">outputs</span><span class="p">:</span> <span class="n">List<span class="p">[</span>Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; dict<a class="reference internal" href="_modules/comet/models/ranking/comet_ranker.html#CometRanker.compute_metrics"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.ranking.comet_ranker.CometRanker.compute_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes WMT19 shared task kendall tau like metric.</p>
</dd></dl>

<dl class="py method">
<dt id="comet.models.ranking.comet_ranker.CometRanker.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">src_tokens</span><span class="p">:</span> <span class="n">None._VariableFunctions.tensor</span></em>, <em class="sig-param"><span class="n">ref_tokens</span><span class="p">:</span> <span class="n">None._VariableFunctions.tensor</span></em>, <em class="sig-param"><span class="n">pos_tokens</span><span class="p">:</span> <span class="n">None._VariableFunctions.tensor</span></em>, <em class="sig-param"><span class="n">neg_tokens</span><span class="p">:</span> <span class="n">None._VariableFunctions.tensor</span></em>, <em class="sig-param"><span class="n">src_lengths</span><span class="p">:</span> <span class="n">None._VariableFunctions.tensor</span></em>, <em class="sig-param"><span class="n">ref_lengths</span><span class="p">:</span> <span class="n">None._VariableFunctions.tensor</span></em>, <em class="sig-param"><span class="n">pos_lengths</span><span class="p">:</span> <span class="n">None._VariableFunctions.tensor</span></em>, <em class="sig-param"><span class="n">neg_lengths</span><span class="p">:</span> <span class="n">None._VariableFunctions.tensor</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span> &#x2192; Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><a class="reference internal" href="_modules/comet/models/ranking/comet_ranker.html#CometRanker.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.ranking.comet_ranker.CometRanker.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that encodes the anchor, positive samples and negative samples
and returns embeddings for the triplet.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>src_tokens</strong> – anchor sequences [batch_size x anchor_seq_len]</p></li>
<li><p><strong>ref_tokens</strong> – anchor sequences [batch_size x anchor_seq_len]</p></li>
<li><p><strong>pos_tokens</strong> – positive sequences [batch_size x pos_seq_len]</p></li>
<li><p><strong>neg_tokens</strong> – negative sequences [batch_size x neg_seq_len]</p></li>
<li><p><strong>src_lengths</strong> – anchor lengths [batch_size]</p></li>
<li><p><strong>ref_lengths</strong> – anchor lengths [batch_size]</p></li>
<li><p><strong>pos_lengths</strong> – positive lengths [batch_size]</p></li>
<li><p><strong>neg_lengths</strong> – negative lengths [batch_size]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dictionary with model outputs to be passed to the loss function.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.ranking.comet_ranker.CometRanker.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">samples</span><span class="p">:</span> <span class="n">Dict<span class="p">[</span>str<span class="p">, </span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">cuda</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em>, <em class="sig-param"><span class="n">show_progress</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/comet/models/ranking/comet_ranker.html#CometRanker.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.ranking.comet_ranker.CometRanker.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that runs a model prediction,</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> – List of dictionaries with ‘mt’ and ‘ref’ keys.</p></li>
<li><p><strong>cuda</strong> – Flag that runs inference using 1 single GPU.</p></li>
<li><p><strong>show_progress</strong> – Flag to show progress during inference of multiple examples.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dictionary with model outputs</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="comet.models.ranking.comet_ranker.CometRanker.prepare_sample">
<code class="sig-name descname">prepare_sample</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sample</span><span class="p">:</span> <span class="n">List<span class="p">[</span>Dict<span class="p">[</span>str<span class="p">, </span>Union<span class="p">[</span>str<span class="p">, </span>float<span class="p">]</span><span class="p">]</span><span class="p">]</span></span></em>, <em class="sig-param"><span class="n">inference</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em><span class="sig-paren">)</span> &#x2192; Union<span class="p">[</span>Tuple<span class="p">[</span>Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><span class="p">, </span>None<span class="p">]</span><span class="p">, </span>List<span class="p">[</span>Dict<span class="p">[</span>str<span class="p">, </span>torch.Tensor<span class="p">]</span><span class="p">]</span><span class="p">]</span><a class="reference internal" href="_modules/comet/models/ranking/comet_ranker.html#CometRanker.prepare_sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.models.ranking.comet_ranker.CometRanker.prepare_sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that prepares a sample to input the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sample</strong> – list of dictionaries.</p></li>
<li><p><strong>inference</strong> – If set to to False, then the model expects
a MT and reference instead of anchor, pos, and neg segments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tuple with a dictionary containing the model inputs and None OR List
with source, MT and reference tokenized and vectorized.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>
<div class="section" id="module-comet.modules.feedforward">
<span id="auxiliar-modules"></span><h2>Auxiliar Modules<a class="headerlink" href="#module-comet.modules.feedforward" title="Permalink to this headline">¶</a></h2>
<div class="section" id="feed-forward">
<h3>Feed Forward<a class="headerlink" href="#feed-forward" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>Simple Feed Forward Neural Network module that can be used for classification or regression</p>
</div></blockquote>
<dl class="py class">
<dt id="comet.modules.feedforward.FeedForward">
<em class="property">class </em><code class="sig-prename descclassname">comet.modules.feedforward.</code><code class="sig-name descname">FeedForward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">in_dim</span><span class="p">:</span> <span class="n">int</span></em>, <em class="sig-param"><span class="n">out_dim</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">1</span></em>, <em class="sig-param"><span class="n">hidden_sizes</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="default_value">'3072,1536,768'</span></em>, <em class="sig-param"><span class="n">activations</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="default_value">'Sigmoid'</span></em>, <em class="sig-param"><span class="n">final_activation</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="default_value">'Sigmoid'</span></em>, <em class="sig-param"><span class="n">dropout</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">0.0</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/comet/modules/feedforward.html#FeedForward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.modules.feedforward.FeedForward" title="Permalink to this definition">¶</a></dt>
<dd><p>Feed Forward Neural Network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_dim</strong> – Number input features.</p></li>
<li><p><strong>out_dim</strong> – Number of output features. Default is just a score.</p></li>
<li><p><strong>hidden_sizes</strong> – list with the size of the hidden layers.
This parameter can also be a string with the sizes splited by a comma.</p></li>
<li><p><strong>activations</strong> – Name of the activation function to be used in the hidden layers.</p></li>
<li><p><strong>final_activation</strong> – Name of the final activation function or False if we dont
want a final activation.</p></li>
<li><p><strong>dropout</strong> – dropout to be used in the hidden layers.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="comet.modules.feedforward.FeedForward.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">in_features</span><span class="p">:</span> <span class="n">torch.Tensor</span></em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="_modules/comet/modules/feedforward.html#FeedForward.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.modules.feedforward.FeedForward.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

</div>
<span class="target" id="module-comet.modules.scalar_mix"></span><div class="section" id="layer-wise-attention-mechanism">
<h3>Layer-Wise Attention Mechanism<a class="headerlink" href="#layer-wise-attention-mechanism" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>Computes a parameterised scalar mixture of N tensors, <cite>mixture = gamma * sum(s_k * tensor_k)</cite>
where <cite>s = softmax(w)</cite>, with <cite>w</cite> and <cite>gamma</cite> scalar parameters.</p>
<p>If <cite>do_layer_norm=True</cite> then apply layer normalization to each tensor before weighting.</p>
<p>If <cite>dropout &gt; 0</cite>, then for each scalar weight, adjust its softmax weight mass to 0 with
the dropout probability (i.e., setting the unnormalized weight to -inf). This effectively
should redistribute dropped probability mass to all other weights.</p>
<dl class="simple">
<dt>Original implementation:</dt><dd><ul class="simple">
<li><p><a class="reference external" href="https://github.com/Hyperparticle/udify">https://github.com/Hyperparticle/udify</a></p></li>
</ul>
</dd>
</dl>
</div></blockquote>
<dl class="py class">
<dt id="comet.modules.scalar_mix.ScalarMixWithDropout">
<em class="property">class </em><code class="sig-prename descclassname">comet.modules.scalar_mix.</code><code class="sig-name descname">ScalarMixWithDropout</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">mixture_size</span><span class="p">:</span> <span class="n">int</span></em>, <em class="sig-param"><span class="n">do_layer_norm</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em>, <em class="sig-param"><span class="n">initial_scalar_parameters</span><span class="p">:</span> <span class="n">list</span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">trainable</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">True</span></em>, <em class="sig-param"><span class="n">dropout</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">dropout_value</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">- 1e+20</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/comet/modules/scalar_mix.html#ScalarMixWithDropout"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.modules.scalar_mix.ScalarMixWithDropout" title="Permalink to this definition">¶</a></dt>
<dd><dl class="py method">
<dt id="comet.modules.scalar_mix.ScalarMixWithDropout.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">tensors</span><span class="p">:</span> <span class="n">List<span class="p">[</span>torch.Tensor<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">mask</span><span class="p">:</span> <span class="n">torch.Tensor</span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="_modules/comet/modules/scalar_mix.html#ScalarMixWithDropout.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#comet.modules.scalar_mix.ScalarMixWithDropout.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute a weighted average of the <cite>tensors</cite>.  The input tensors an be any shape
with at least two dimensions, but must all be the same shape.
When <cite>do_layer_norm=True</cite>, the <cite>mask</cite> is required input.  If the <cite>tensors</cite> are
dimensioned  <cite>(dim_0, …, dim_{n-1}, dim_n)</cite>, then the <cite>mask</cite> is dimensioned
<cite>(dim_0, …, dim_{n-1})</cite>, as in the typical case with <cite>tensors</cite> of shape
<cite>(batch_size, timesteps, dim)</cite> and <cite>mask</cite> of shape <cite>(batch_size, timesteps)</cite>.
When <cite>do_layer_norm=False</cite> the <cite>mask</cite> is ignored.</p>
</dd></dl>

</dd></dl>

</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
      
        <a href="training.html" class="btn btn-neutral float-left" title="Train your own Metric" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, Unbabel. All rights reserved.Source code available under the AGPL-3.0.

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>